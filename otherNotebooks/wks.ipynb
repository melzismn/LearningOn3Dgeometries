{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melzismn/Digital-Design-2020-2021/blob/master/wks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2yRvI6BmMg7"
      },
      "source": [
        "# ONLY FOR COLAB\n",
        "# Not required in Binder\n",
        "\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y --prefix /usr/local python=3.6 ujson\n",
        "\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
        "\n",
        "import ujson\n",
        "print(ujson.dumps({1:2}))\n",
        "\n",
        "!conda install -c conda-forge igl\n",
        "!conda install -c conda-forge meshplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpI4m_FcmS2V"
      },
      "source": [
        "!pip install --upgrade --force-reinstall Pillow\n",
        "\n",
        "import igl\n",
        "import scipy\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "from meshplot import plot, subplot, interact\n",
        "import meshplot\n",
        "from scipy.sparse.linalg import eigs,eigsh\n",
        "from scipy.sparse import csr_matrix\n",
        "import os \n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rBPjw-0mXTL"
      },
      "source": [
        "def plot_pair(v1, v2, f1, f2, c1, c2, color_ops = {}):\n",
        "    # Compute a scale factor\n",
        "    M1 = igl.massmatrix(v1, f1, igl.MASSMATRIX_TYPE_VORONOI)\n",
        "    M2 = igl.massmatrix(v2, f2, igl.MASSMATRIX_TYPE_VORONOI)\n",
        "    scale_factor = np.sqrt(np.sum(M2)/np.sum(M1))\n",
        "\n",
        "    # Align the shapes\n",
        "    v2 = v2 - np.mean(v2,axis=0)\n",
        "    v1_align = v1 * scale_factor + np.mean(v1,axis=0) + [0.7,-0.7,0.0]\n",
        "\n",
        "    # Merge the models\n",
        "    v_all = np.vstack((v1_align, v2))\n",
        "    f_all = np.vstack((f1, f2 + np.max(f1)+1))\n",
        "    c_all = np.vstack((c1, c2))\n",
        "    \n",
        "    plot(v_all, f_all, c_all, shading = color_ops)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGY1lpZGai3v"
      },
      "source": [
        "# Load Shapes\n",
        "v_src, f_src = igl.read_triangle_mesh(os.path.join('.', \"data\", \"tr_reg_089.off\"))\n",
        "\n",
        "L_src = -igl.cotmatrix(v_src, f_src)\n",
        "M_src = igl.massmatrix(v_src, f_src, igl.MASSMATRIX_TYPE_VORONOI)\n",
        "\n",
        "try:\n",
        "    evals_src, evecs_src = eigsh(L_src, 200, M_src, sigma=0.0, which='LM', maxiter=1e9, tol=1.e-15)\n",
        "except:\n",
        "    evals_src, evecs_src = eigsh(L_src- 1e-8* scipy.sparse.identity(v_src.shape[0]), 200,\n",
        "                         M_src, sigma=0.0, which='LM', maxiter=1e9, tol=1.e-15)\n",
        "\n",
        "evals_src = evals_src.astype(np.float32)\n",
        "evals_src = evals_src.astype(np.float32)\n",
        "\n",
        "v_tar, f_tar = igl.read_triangle_mesh(os.path.join('.', \"data\", \"tr_reg_090.off\"))\n",
        "\n",
        "L_tar = -igl.cotmatrix(v_tar, f_tar)\n",
        "M_tar = igl.massmatrix(v_tar, f_tar, igl.MASSMATRIX_TYPE_VORONOI)\n",
        "\n",
        "try:\n",
        "    evals_tar, evecs_tar = eigsh(L_tar, 200, M_tar, sigma=0.0, which='LM', maxiter=1e9, tol=1.e-15)\n",
        "except:\n",
        "    evals_tar, evecs_tar = eigsh(L_tar- 1e-8* scipy.sparse.identity(v_tar.shape[0]), 200,\n",
        "                         M_src, sigma=0.0, which='LM', maxiter=1e9, tol=1.e-15)\n",
        "    \n",
        "evals_tar = evals_tar.astype(np.float32)\n",
        "evals_tar = evals_tar.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXJB3W56qLKr"
      },
      "source": [
        "# WKS\n",
        "\n",
        "We will use the Wave Kernel Signature (WKS) descriptor to do the matching. Recall the formula:\n",
        "\n",
        "$K_E(x,x) = \\sum\\limits_{l=1}^{\\infty}e^{- \\frac{(log(E) - log(\\lambda_l))^2}{2\\sigma^2}} \\phi_l(x)^2 $\n",
        "\n",
        "Where:\n",
        "- $sigma = 7 \\delta$\n",
        "- $delta =  (e_{max} - e{min})/ M$\n",
        "- $e_{max} = log(E_N) - 2\\sigma$\n",
        "- $e_{min} = log(E_1) + 2\\sigma$\n",
        "- $E_N$ is the max eigenvalue in absolute value\n",
        "- $E_1$ is the min non-zero eigenvalue in absolute value\n",
        "- $M$ is the number of WKS scales\n",
        "\n",
        "The tasks are:\n",
        "- Read the meshes, compute the LBO eigenvectors\n",
        "- Define the WKS computation\n",
        "- Visualize the WKS scales on meshes\n",
        "- Perform the matching using WKS (Nearest-Neighbor in the descriptor space)\n",
        "- Visualize the matching (and compute the error)\n",
        "\n",
        "Are the descriptors coherent among the shapes, for different descriptor scales? Is the matching good? We can change the number of descriptors: does it impact the matching?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa35jY3hpwW5"
      },
      "source": [
        "def WKS(vertices, faces, evals, evecs, wks_size, variance):\n",
        "    # Number of vertices\n",
        "    n = vertices.shape[0]\n",
        "    WKS = np.zeros((n,wks_size))\n",
        "\n",
        "    # Just for numerical stability\n",
        "    evals[evals<1e-6] = 1e-6\n",
        "\n",
        "    # log(E)\n",
        "    log_E = np.log(evals).T\n",
        "\n",
        "    # Define the energies step\n",
        "    e = np.linspace(log_E[1], np.max(log_E)/1.02, wks_size)\n",
        "\n",
        "    # Compute the sigma\n",
        "    sigma = (e[1]-e[0]) * variance\n",
        "    C = np.zeros((wks_size,1))\n",
        "\n",
        "    for i in np.arange(0,wks_size):\n",
        "        # Computing WKS\n",
        "        WKS[:,i] = np.sum(\n",
        "            (evecs)**2 * np.tile( np.exp((-(e[i] - log_E)**2) / (2*sigma**2)),(n,1)), axis=1)\n",
        "        \n",
        "        # Noramlization\n",
        "        C[i] = np.sum(np.exp((-(e[i]-log_E)**2)/(2*sigma**2)))\n",
        "        \n",
        "    WKS = np.divide(WKS,np.tile(C,(1,n)).T)\n",
        "    return WKS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBG2ZKlHp1Jv"
      },
      "source": [
        "# Computing the descriptors for the two shapes\n",
        "d_src = WKS(v_src, f_src, evals_src, evecs_src, 100, 7)\n",
        "d_tar = WKS(v_tar, f_tar, evals_tar, evecs_tar, 100, 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfu49Cf01Xec"
      },
      "source": [
        "# Visualizing descriptors\n",
        "i = 2\n",
        "plot_pair(v_src, v_tar, f_src, f_tar, d_src[:,i:i+1], d_tar[:,i:i+1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWHhseWx1ZDm"
      },
      "source": [
        "# Nearest Neighbor\n",
        "treesearch = sp.spatial.cKDTree(d_tar)\n",
        "p2p = treesearch.query(d_src, k=1)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyRvBccW1aNc"
      },
      "source": [
        "# To see the quality of the matching we plot a function on one shape and we transfer it to the other\n",
        "funz_ = (v_tar - np.min(v_tar,0))/np.tile((np.max(v_tar,0)-np.min(v_tar,0)),(np.size(v_tar,0),1));\n",
        "colors = np.cos(funz_);\n",
        "funz_tar = (colors-np.min(colors))/(np.max(colors) - np.min(colors));\n",
        "funz_src = funz_tar[p2p]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN3sxDPK1euO"
      },
      "source": [
        "# Plot and (euclidean) error evaluation\n",
        "funz_src = funz_tar[p2p]\n",
        "plot_pair(v_src, v_tar, f_src, f_tar, funz_src,funz_tar)\n",
        "err = np.sum(np.square(v_tar - v_tar[p2p,:]))\n",
        "print(err)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
